---
permalink: /
title: "Welcome stranger, take a glimpse into my brain and all things that excite me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

![Illustration](/images/banner.gif){: .align-right width="300px"}

ğŸ‘¨ğŸ»â€ğŸ’» I'm a final year graduate student at the Georgia Tech.

ğŸ”¬ I have a strong passion for learning and continuously absorbing new advancements in AI, Machine Learning, and Software Engineering.

ğŸ“š I love learning new things currently spending my weekends reading the thriller that is ['Programming Massively Parallel Processors'](https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0124159923) and going down the CUDA programming rabbit hole thanks to [Umar Jamil](https://x.com/hkproj): check out my progress [here](https://github.com/p-kris10/100DaysofGPU) as I take on the task to write complex CUDA kernels for 100 days to get the maximum juice out of GPUs

ğŸƒ I am also interested in Running. My Full Marathon Personal Best is 3:49. Check me out on [strava](https://strava.app.link/v1seLviw3Qb)

# Some cherry picked stuff I am proud of

## ğŸ¤– Open Source Contributions
I have experience contributing to [HuggingFace Transformers](https://github.com/huggingface/transformers/pull/31131). Hugging Face Transformers is the go to open-source library for state-of-the-art machine learning models (since you have wandered here on my profile you prolly already knew that)


## ğŸ“œ Reimplementing and Reproducing Papers
I love research at the intersection of vision and Language so I have dabbled into reproducing results from both domains that interested me.


Checkout my implementation of [Neural Style Transfer from scratch](https://github.com/p-kris10/Universal-NST/blob/main/UniversalNST.ipynb) (This was way before DALL-E entered the scene, love going back to basics and understanding stuff from first pricniples). Checkout my colab notebook where you can record a video from webcam and apply the style of your choice in realtime!. Here are some of the results from this : 

<div style="display: flex; gap: 10px;">
    <img src="/images/bridge.png" alt="Apple">
    <img src="/images/style.png" alt="Pen">
    <img src="/images/result.png" alt="ApplePen">
</div>


I also modified the Meta's Fairseq library  to support CPT  and implemented both post-training quantization and quantization-aware fine-tuning on a RoBERTa model with mixed precision while optimizing multi-GPU communication primitives and profiling pipeline parallelism to enhance training throughput and reduce memory overhead. check out the code [here](https://github.com/p-kris10/Universal-NST/blob/main/UniversalNST.ipynb)



## ğŸ“š Teaching and Community Contributions
- Teaching Assistant for Computer Vision at Georgia Tech for the past four semesters, where I have been passionate about mentoring and guiding students in the field.

- I enjoy sharing knowledge and insights through my [Medium blog](https://medium.com/@26pkristen), where I have published several articles on AI and ML, with more content in the worksâ€”stay tuned!